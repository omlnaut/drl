{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import common\n",
    "from nb_export.core import build_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import ptan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = common.HYPERPARAMS['pong']\n",
    "device = torch.device('cuda')\n",
    "\n",
    "env = gym.make(params.env_name)\n",
    "env = ptan.common.wrappers.wrap_dqn(env)\n",
    "env.seed(common.SEED)\n",
    "\n",
    "net = common.DQN(env.observation_space.shape, env.action_space.n).to(device)\n",
    "tgt_net = ptan.agent.TargetNet(net)\n",
    "\n",
    "selector = ptan.actions.EpsilonGreedyActionSelector(epsilon=params.epsilon_start)\n",
    "epsilon_tracker = common.EpsilonTracker(selector, params)\n",
    "agent = ptan.agent.DQNAgent(net, selector, device=device)\n",
    "\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(env, agent, params.gamma, steps_count=params.n)\n",
    "buffer = ptan.experience.ExperienceReplayBuffer(exp_source, params.replay_size)\n",
    "opt = optim.Adam(net.parameters(), params.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done populating\n",
      "Episode: 1 | Reward: -20.0 | Epsilon: 1.0 | Elapsed: 31.85182285308838\n",
      "Episode: 2 | Reward: -21.0 | Epsilon: 1.0 | Elapsed: 1.9073486328125e-06\n",
      "Episode: 3 | Reward: -21.0 | Epsilon: 1.0 | Elapsed: 1.1920928955078125e-06\n",
      "Episode: 4 | Reward: -20.0 | Epsilon: 1.0 | Elapsed: 9.5367431640625e-07\n",
      "Episode: 5 | Reward: -20.0 | Epsilon: 1.0 | Elapsed: 9.5367431640625e-07\n",
      "Episode: 6 | Reward: -20.0 | Epsilon: 1.0 | Elapsed: 1.1920928955078125e-06\n",
      "Episode: 7 | Reward: -18.0 | Epsilon: 1.0 | Elapsed: 9.5367431640625e-07\n",
      "Episode: 8 | Reward: -21.0 | Epsilon: 1.0 | Elapsed: 9.5367431640625e-07\n",
      "Episode: 9 | Reward: -20.0 | Epsilon: 1.0 | Elapsed: 9.5367431640625e-07\n",
      "Episode: 10 | Reward: -21.0 | Epsilon: 1.0 | Elapsed: 9.5367431640625e-07\n",
      "Episode: 11 | Reward: -19.0 | Epsilon: 0.99617 | Elapsed: 6.208643674850464\n",
      "Sync\n",
      "Episode: 12 | Reward: -21.0 | Epsilon: 0.98831 | Elapsed: 13.85500431060791\n",
      "Sync\n",
      "Episode: 13 | Reward: -20.0 | Epsilon: 0.97915 | Elapsed: 15.892884969711304\n",
      "Episode: 14 | Reward: -21.0 | Epsilon: 0.97032 | Elapsed: 14.893805503845215\n",
      "Sync\n",
      "Episode: 15 | Reward: -19.0 | Epsilon: 0.96058 | Elapsed: 16.70386791229248\n",
      "Sync\n",
      "Episode: 16 | Reward: -21.0 | Epsilon: 0.9522 | Elapsed: 14.2164306640625\n",
      "Sync\n",
      "Episode: 17 | Reward: -20.0 | Epsilon: 0.94209 | Elapsed: 17.598912000656128\n",
      "Sync\n",
      "Sync\n",
      "Episode: 18 | Reward: -17.0 | Epsilon: 0.92958 | Elapsed: 21.607357263565063\n",
      "Episode: 19 | Reward: -20.0 | Epsilon: 0.92125 | Elapsed: 14.445093870162964\n",
      "Sync\n",
      "Episode: 20 | Reward: -19.0 | Epsilon: 0.9103 | Elapsed: 19.333357334136963\n",
      "Sync\n",
      "Sync\n",
      "Episode: 21 | Reward: -19.0 | Epsilon: 0.89991 | Elapsed: 18.088053226470947\n",
      "Episode: 22 | Reward: -20.0 | Epsilon: 0.89003 | Elapsed: 17.141976356506348\n",
      "Sync\n",
      "Episode: 23 | Reward: -21.0 | Epsilon: 0.88246 | Elapsed: 13.056342840194702\n",
      "Sync\n",
      "Episode: 24 | Reward: -20.0 | Epsilon: 0.87349 | Elapsed: 15.100454807281494\n",
      "Sync\n",
      "Episode: 25 | Reward: -21.0 | Epsilon: 0.86563 | Elapsed: 13.608050346374512\n",
      "Sync\n",
      "Episode: 26 | Reward: -20.0 | Epsilon: 0.85683 | Elapsed: 16.62100839614868\n",
      "Sync\n",
      "Episode: 27 | Reward: -21.0 | Epsilon: 0.84838 | Elapsed: 14.319143533706665\n",
      "Sync\n",
      "Episode: 28 | Reward: -20.0 | Epsilon: 0.83972 | Elapsed: 15.291419744491577\n",
      "Episode: 29 | Reward: -19.0 | Epsilon: 0.83003 | Elapsed: 16.219959497451782\n",
      "Sync\n",
      "Sync\n",
      "Episode: 30 | Reward: -19.0 | Epsilon: 0.81986 | Elapsed: 17.984842777252197\n",
      "Episode: 31 | Reward: -20.0 | Epsilon: 0.8109 | Elapsed: 14.946674346923828\n",
      "Sync\n",
      "Episode: 32 | Reward: -19.0 | Epsilon: 0.80078 | Elapsed: 17.628326177597046\n",
      "Sync\n",
      "Sync\n",
      "Episode: 33 | Reward: -21.0 | Epsilon: 0.78958 | Elapsed: 19.587050914764404\n",
      "Episode: 34 | Reward: -21.0 | Epsilon: 0.78034 | Elapsed: 15.02715539932251\n",
      "Sync\n",
      "Episode: 35 | Reward: -19.0 | Epsilon: 0.77039 | Elapsed: 17.919998168945312\n",
      "Sync\n",
      "Episode: 36 | Reward: -20.0 | Epsilon: 0.76113 | Elapsed: 15.79759168624878\n",
      "Sync\n",
      "Episode: 37 | Reward: -20.0 | Epsilon: 0.75186 | Elapsed: 15.78001880645752\n",
      "Sync\n",
      "Episode: 38 | Reward: -20.0 | Epsilon: 0.74268 | Elapsed: 16.16997456550598\n",
      "Sync\n",
      "Episode: 39 | Reward: -20.0 | Epsilon: 0.73297 | Elapsed: 16.930787324905396\n",
      "Sync\n",
      "Episode: 40 | Reward: -19.0 | Epsilon: 0.72044 | Elapsed: 21.514273405075073\n",
      "Sync\n",
      "Episode: 41 | Reward: -21.0 | Epsilon: 0.71191 | Elapsed: 14.86338996887207\n",
      "Sync\n",
      "Episode: 42 | Reward: -19.0 | Epsilon: 0.70034 | Elapsed: 19.8059561252594\n",
      "Sync\n",
      "Episode: 43 | Reward: -21.0 | Epsilon: 0.6906399999999999 | Elapsed: 16.608424425125122\n",
      "Sync\n",
      "Sync\n",
      "Episode: 44 | Reward: -19.0 | Epsilon: 0.67883 | Elapsed: 20.938555002212524\n",
      "Sync\n",
      "Episode: 45 | Reward: -18.0 | Epsilon: 0.66631 | Elapsed: 22.518092393875122\n",
      "Sync\n",
      "Episode: 46 | Reward: -19.0 | Epsilon: 0.654 | Elapsed: 21.85628843307495\n",
      "Sync\n",
      "Episode: 47 | Reward: -18.0 | Epsilon: 0.64177 | Elapsed: 21.283046007156372\n",
      "Sync\n",
      "Episode: 48 | Reward: -20.0 | Epsilon: 0.63024 | Elapsed: 19.83521032333374\n",
      "Sync\n",
      "Sync\n",
      "Episode: 49 | Reward: -17.0 | Epsilon: 0.61576 | Elapsed: 25.476495265960693\n",
      "Sync\n",
      "Episode: 50 | Reward: -16.0 | Epsilon: 0.60039 | Elapsed: 26.33673858642578\n",
      "Sync\n",
      "Sync\n",
      "Episode: 51 | Reward: -19.0 | Epsilon: 0.5899 | Elapsed: 17.976396799087524\n",
      "Sync\n",
      "Episode: 52 | Reward: -20.0 | Epsilon: 0.57821 | Elapsed: 20.948900938034058\n",
      "Sync\n",
      "Episode: 53 | Reward: -20.0 | Epsilon: 0.56734 | Elapsed: 18.95744752883911\n",
      "Sync\n",
      "Episode: 54 | Reward: -18.0 | Epsilon: 0.55374 | Elapsed: 23.26423192024231\n",
      "Sync\n",
      "Episode: 55 | Reward: -20.0 | Epsilon: 0.54245 | Elapsed: 19.944308519363403\n",
      "Sync\n",
      "Sync\n",
      "Episode: 56 | Reward: -16.0 | Epsilon: 0.5277499999999999 | Elapsed: 25.53136420249939\n",
      "Sync\n",
      "Episode: 57 | Reward: -17.0 | Epsilon: 0.51257 | Elapsed: 25.86719560623169\n",
      "Sync\n",
      "Episode: 58 | Reward: -17.0 | Epsilon: 0.50025 | Elapsed: 21.62451410293579\n",
      "Sync\n",
      "Sync\n",
      "Episode: 59 | Reward: -19.0 | Epsilon: 0.48867000000000005 | Elapsed: 19.895227193832397\n",
      "Sync\n",
      "Episode: 60 | Reward: -18.0 | Epsilon: 0.474 | Elapsed: 25.445972681045532\n",
      "Sync\n",
      "Sync\n",
      "Episode: 61 | Reward: -14.0 | Epsilon: 0.45482999999999996 | Elapsed: 33.21626043319702\n",
      "Sync\n",
      "Episode: 62 | Reward: -18.0 | Epsilon: 0.44101 | Elapsed: 24.134080410003662\n",
      "Sync\n",
      "Sync\n",
      "Episode: 63 | Reward: -19.0 | Epsilon: 0.4274 | Elapsed: 22.930206060409546\n",
      "Sync\n",
      "Sync\n",
      "Episode: 64 | Reward: -12.0 | Epsilon: 0.40730999999999995 | Elapsed: 34.335174322128296\n",
      "Sync\n",
      "Episode: 65 | Reward: -19.0 | Epsilon: 0.39375000000000004 | Elapsed: 23.212738513946533\n",
      "Sync\n",
      "Episode: 66 | Reward: -17.0 | Epsilon: 0.38112999999999997 | Elapsed: 21.187276363372803\n",
      "Sync\n",
      "Sync\n",
      "Episode: 67 | Reward: -18.0 | Epsilon: 0.36561 | Elapsed: 26.851083040237427\n",
      "Sync\n",
      "Episode: 68 | Reward: -16.0 | Epsilon: 0.35102 | Elapsed: 25.68147587776184\n",
      "Sync\n",
      "Sync\n",
      "Episode: 69 | Reward: -17.0 | Epsilon: 0.33335000000000004 | Elapsed: 31.591538190841675\n",
      "Sync\n",
      "Sync\n",
      "Episode: 70 | Reward: -20.0 | Epsilon: 0.31732000000000005 | Elapsed: 29.0086669921875\n",
      "Sync\n",
      "Episode: 71 | Reward: -15.0 | Epsilon: 0.30001999999999995 | Elapsed: 29.55504035949707\n",
      "Sync\n",
      "Sync\n",
      "Episode: 72 | Reward: -14.0 | Epsilon: 0.28139000000000003 | Elapsed: 33.10945725440979\n",
      "Sync\n",
      "Sync\n",
      "Episode: 73 | Reward: -19.0 | Epsilon: 0.26673 | Elapsed: 26.21438717842102\n",
      "Sync\n",
      "Sync\n",
      "Episode: 74 | Reward: -9.0 | Epsilon: 0.24270999999999998 | Elapsed: 43.74677109718323\n",
      "Sync\n",
      "Sync\n",
      "Episode: 75 | Reward: -16.0 | Epsilon: 0.22392 | Elapsed: 33.66526961326599\n",
      "Sync\n",
      "Sync\n",
      "Episode: 76 | Reward: -14.0 | Epsilon: 0.20498000000000005 | Elapsed: 33.827908992767334\n",
      "Sync\n",
      "Sync\n",
      "Episode: 77 | Reward: -9.0 | Epsilon: 0.18416999999999994 | Elapsed: 37.056723833084106\n",
      "Sync\n",
      "Sync\n",
      "Episode: 78 | Reward: -13.0 | Epsilon: 0.16549999999999998 | Elapsed: 33.48700451850891\n",
      "Sync\n",
      "Sync\n",
      "Episode: 79 | Reward: -12.0 | Epsilon: 0.14122999999999997 | Elapsed: 42.01490235328674\n",
      "Sync\n",
      "Sync\n",
      "Episode: 80 | Reward: -17.0 | Epsilon: 0.12246000000000001 | Elapsed: 33.49050307273865\n",
      "Sync\n",
      "Sync\n",
      "Episode: 81 | Reward: -11.0 | Epsilon: 0.10201000000000005 | Elapsed: 35.42267847061157\n",
      "Sync\n",
      "Sync\n",
      "Episode: 82 | Reward: -20.0 | Epsilon: 0.08697999999999995 | Elapsed: 27.48096513748169\n",
      "Sync\n",
      "Sync\n",
      "Episode: 83 | Reward: -18.0 | Epsilon: 0.06598000000000004 | Elapsed: 36.92431974411011\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 84 | Reward: 1.0 | Epsilon: 0.038250000000000006 | Elapsed: 49.02618193626404\n",
      "Sync\n",
      "Sync\n",
      "Episode: 85 | Reward: -19.0 | Epsilon: 0.02 | Elapsed: 33.09259748458862\n",
      "Sync\n",
      "Sync\n",
      "Episode: 86 | Reward: -7.0 | Epsilon: 0.02 | Elapsed: 45.86321806907654\n",
      "Sync\n",
      "Episode: 87 | Reward: -21.0 | Epsilon: 0.02 | Elapsed: 21.715023279190063\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 88 | Reward: -1.0 | Epsilon: 0.02 | Elapsed: 47.823763608932495\n",
      "Sync\n",
      "Sync\n",
      "Episode: 89 | Reward: -20.0 | Epsilon: 0.02 | Elapsed: 37.97676706314087\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 90 | Reward: -13.0 | Epsilon: 0.02 | Elapsed: 45.27424693107605\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 91 | Reward: -5.0 | Epsilon: 0.02 | Elapsed: 47.82710313796997\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 92 | Reward: -2.0 | Epsilon: 0.02 | Elapsed: 56.33287978172302\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 93 | Reward: 3.0 | Epsilon: 0.02 | Elapsed: 57.82531666755676\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 94 | Reward: 7.0 | Epsilon: 0.02 | Elapsed: 51.32473802566528\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 95 | Reward: 5.0 | Epsilon: 0.02 | Elapsed: 51.673662185668945\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 96 | Reward: 1.0 | Epsilon: 0.02 | Elapsed: 55.998632192611694\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 97 | Reward: -1.0 | Epsilon: 0.02 | Elapsed: 58.768311977386475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 98 | Reward: 4.0 | Epsilon: 0.02 | Elapsed: 52.0904541015625\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 99 | Reward: 4.0 | Epsilon: 0.02 | Elapsed: 51.346985816955566\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 100 | Reward: 4.0 | Epsilon: 0.02 | Elapsed: 54.168370723724365\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 101 | Reward: -1.0 | Epsilon: 0.02 | Elapsed: 57.62851047515869\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 102 | Reward: 3.0 | Epsilon: 0.02 | Elapsed: 52.81425213813782\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 103 | Reward: 4.0 | Epsilon: 0.02 | Elapsed: 63.71525287628174\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 104 | Reward: 11.0 | Epsilon: 0.02 | Elapsed: 47.79267144203186\n",
      "Sync\n",
      "Sync\n",
      "Episode: 105 | Reward: 12.0 | Epsilon: 0.02 | Elapsed: 48.96186542510986\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 106 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 42.41900992393494\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 107 | Reward: 9.0 | Epsilon: 0.02 | Elapsed: 45.96444082260132\n",
      "Sync\n",
      "Sync\n",
      "Episode: 108 | Reward: 16.0 | Epsilon: 0.02 | Elapsed: 39.21913433074951\n",
      "Sync\n",
      "Sync\n",
      "Episode: 109 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 39.3206570148468\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 110 | Reward: 9.0 | Epsilon: 0.02 | Elapsed: 54.980021476745605\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 111 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 49.47696781158447\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 112 | Reward: 6.0 | Epsilon: 0.02 | Elapsed: 56.896342754364014\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 113 | Reward: 12.0 | Epsilon: 0.02 | Elapsed: 47.766568422317505\n",
      "Sync\n",
      "Sync\n",
      "Episode: 114 | Reward: 12.0 | Epsilon: 0.02 | Elapsed: 44.70460629463196\n",
      "Sync\n",
      "Sync\n",
      "Episode: 115 | Reward: 17.0 | Epsilon: 0.02 | Elapsed: 40.219714641571045\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 116 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 36.357830286026\n",
      "Sync\n",
      "Sync\n",
      "Episode: 117 | Reward: 12.0 | Epsilon: 0.02 | Elapsed: 48.65412878990173\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 118 | Reward: 15.0 | Epsilon: 0.02 | Elapsed: 43.6184356212616\n",
      "Sync\n",
      "Sync\n",
      "Episode: 119 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 35.64780259132385\n",
      "Sync\n",
      "Sync\n",
      "Episode: 120 | Reward: 17.0 | Epsilon: 0.02 | Elapsed: 36.061360597610474\n",
      "Sync\n",
      "Sync\n",
      "Episode: 121 | Reward: 16.0 | Epsilon: 0.02 | Elapsed: 46.88178491592407\n",
      "Sync\n",
      "Sync\n",
      "Episode: 122 | Reward: 19.0 | Epsilon: 0.02 | Elapsed: 33.603917598724365\n",
      "Sync\n",
      "Sync\n",
      "Episode: 123 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 35.22837162017822\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 124 | Reward: 13.0 | Epsilon: 0.02 | Elapsed: 43.76394200325012\n",
      "Sync\n",
      "Sync\n",
      "Episode: 125 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 43.183159828186035\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 126 | Reward: 13.0 | Epsilon: 0.02 | Elapsed: 44.433303356170654\n",
      "Sync\n",
      "Sync\n",
      "Episode: 127 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 35.96401643753052\n",
      "Sync\n",
      "Sync\n",
      "Episode: 128 | Reward: 15.0 | Epsilon: 0.02 | Elapsed: 37.23834943771362\n",
      "Sync\n",
      "Sync\n",
      "Episode: 129 | Reward: 16.0 | Epsilon: 0.02 | Elapsed: 39.567485094070435\n",
      "Sync\n",
      "Sync\n",
      "Episode: 130 | Reward: 15.0 | Epsilon: 0.02 | Elapsed: 41.79672956466675\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 131 | Reward: 12.0 | Epsilon: 0.02 | Elapsed: 40.52075695991516\n",
      "Sync\n",
      "Sync\n",
      "Episode: 132 | Reward: 19.0 | Epsilon: 0.02 | Elapsed: 34.28605556488037\n",
      "Sync\n",
      "Sync\n",
      "Episode: 133 | Reward: 17.0 | Epsilon: 0.02 | Elapsed: 34.66539239883423\n",
      "Sync\n",
      "Sync\n",
      "Episode: 134 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 38.73289895057678\n",
      "Sync\n",
      "Sync\n",
      "Episode: 135 | Reward: 15.0 | Epsilon: 0.02 | Elapsed: 39.224106311798096\n",
      "Sync\n",
      "Sync\n",
      "Sync\n",
      "Episode: 136 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 44.69362258911133\n",
      "Sync\n",
      "Sync\n",
      "Episode: 137 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 31.70862054824829\n",
      "Sync\n",
      "Sync\n",
      "Episode: 138 | Reward: 15.0 | Epsilon: 0.02 | Elapsed: 41.47822856903076\n",
      "Sync\n",
      "Sync\n",
      "Episode: 139 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 35.166651487350464\n",
      "Sync\n",
      "Sync\n",
      "Episode: 140 | Reward: 20.0 | Epsilon: 0.02 | Elapsed: 27.81442618370056\n",
      "Sync\n",
      "Sync\n",
      "Episode: 141 | Reward: 19.0 | Epsilon: 0.02 | Elapsed: 37.345776319503784\n",
      "Sync\n",
      "Sync\n",
      "Episode: 142 | Reward: 14.0 | Epsilon: 0.02 | Elapsed: 39.75580549240112\n",
      "Sync\n",
      "Sync\n",
      "Episode: 143 | Reward: 19.0 | Epsilon: 0.02 | Elapsed: 33.37691640853882\n",
      "Sync\n",
      "Sync\n",
      "Episode: 144 | Reward: 19.0 | Epsilon: 0.02 | Elapsed: 33.189571380615234\n",
      "Sync\n",
      "Sync\n",
      "Episode: 145 | Reward: 18.0 | Epsilon: 0.02 | Elapsed: 35.16577363014221\n",
      "Sync\n",
      "Sync\n",
      "Episode: 146 | Reward: 20.0 | Epsilon: 0.02 | Elapsed: 34.74471831321716\n",
      "Sync\n",
      "Sync\n",
      "Episode: 147 | Reward: 17.0 | Epsilon: 0.02 | Elapsed: 37.601696252822876\n",
      "Sync\n",
      "Sync\n",
      "Episode: 148 | Reward: 20.0 | Epsilon: 0.02 | Elapsed: 29.93872594833374\n",
      "Sync\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c1f74ad3b4ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtime_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplay_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/drl/chapter8/common.py\u001b[0m in \u001b[0;36mbatch_generator\u001b[0;34m(buffer, initial, batch_size)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done populating'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/ptan-0.6-py3.8.egg/ptan/experience.py\u001b[0m in \u001b[0;36mpopulate\u001b[0;34m(self, samples)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \"\"\"\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_source_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/ptan-0.6-py3.8.egg/ptan/experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mExperienceSourceFirstLast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                 \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/ptan-0.6-py3.8.egg/ptan/experience.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m                     \u001b[0mstates_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstates_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mstates_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_agent_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mg_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/ptan-0.6-py3.8.egg/ptan/agent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, states, agent_states)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0magent_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/ptan-0.6-py3.8.egg/ptan/agent.py\u001b[0m in \u001b[0;36mdefault_states_preprocessor\u001b[0;34m(states)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \"\"\"\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mnp_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mnp_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/fastai/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_expand_dims_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iteration = 0\n",
    "episode = 0\n",
    "time_begin = time.time()\n",
    "\n",
    "for batch in common.batch_generator(buffer, params.replay_initial, params.batch_size):\n",
    "    iteration += 1\n",
    "    \n",
    "    for reward,steps in exp_source.pop_rewards_steps():\n",
    "        episode += 1\n",
    "        elapsed = time.time() - time_begin\n",
    "        print(f'Episode: {episode} | Reward: {reward} | Epsilon: {selector.epsilon} | Elapsed: {elapsed}')\n",
    "        time_begin = time.time()\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    states, actions, rewards, last_states, dones = common.unpack_batch(batch)\n",
    "\n",
    "    actual_qs = net(states).gather(1, actions.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "    # target\n",
    "    with torch.no_grad():\n",
    "        target_qs = tgt_net.model(last_states).max(dim=1)[0]\n",
    "        target_qs[dones] = 0.0\n",
    "        target = rewards + (params.gamma**params.n)*target_qs.detach()\n",
    "\n",
    "    loss = F.mse_loss(target, actual_qs)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    epsilon_tracker.frame(iteration)\n",
    "    \n",
    "    if iteration%params.target_net_sync==0:\n",
    "        print(\"Sync\")\n",
    "        tgt_net.sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
